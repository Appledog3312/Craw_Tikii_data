import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import psycopg2
import time
from datetime import datetime
import numpy as np
import random
import concurrent.futures
from sklearn.cluster import KMeans
from mlxtend.preprocessing import TransactionEncoder
from mlxtend.frequent_patterns import apriori, association_rules
from dask_ml.preprocessing import Categorizer
# C·∫•u h√¨nh trang
st.set_page_config(
    page_title="Tiki Analytics Dashboard",
    page_icon="üõçÔ∏è",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
    <style>
    .main {
        padding: 0rem 1rem;
    }
    .st-bw {
        background-color: #f0f2f6;
    }
    .stMetric {
        background-color: #ffffff;
        padding: 15px;
        border-radius: 10px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    h1 {
        color: #FF6B6B;
        text-align: center;
        padding: 20px;
    }
    .stPlotlyChart {
        background-color: white;
        padding: 10px;
        border-radius: 10px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        margin-bottom: 20px;
    }
    </style>
    """, unsafe_allow_html=True)

# Kh·ªüi t·∫°o session state
if 'start_idx' not in st.session_state:
    st.session_state.start_idx = 0
    st.session_state.batch_size = random.uniform(20,40)
    st.session_state.total_records = None
    st.session_state.current_data = pd.DataFrame()

def connect_db():
    conn = psycopg2.connect(
        database="data_tiki",
        user="nhanpham",
        password="123456",
        host="localhost",
        port="5432"
    )
    return conn

def get_total_records():
    if st.session_state.total_records is None:
        conn = connect_db()
        cursor = conn.cursor()
        cursor.execute("SELECT COUNT(*) FROM data_product")
        st.session_state.total_records = cursor.fetchone()[0]
        conn.close()
    return st.session_state.total_records

def get_data_batch():
    conn = connect_db()
    query = f"""
    SELECT productid, name, brandname, originalprice, price, 
           discount, discountrate, quantitysold, ratingaverage
    FROM data_product
    LIMIT {st.session_state.batch_size} 
    OFFSET {st.session_state.start_idx}
    """
    df_batch = pd.read_sql(query, conn)
    conn.close()

    # L√†m s·∫°ch d·ªØ li·ªáu: lo·∫°i b·ªè gi√° tr·ªã √¢m ho·∫∑c NaN
    df_batch = df_batch.dropna(subset=["price", "ratingaverage", "quantitysold"])
    df_batch = df_batch[(df_batch["price"] >= 0) & 
                        (df_batch["ratingaverage"] > 0) & 
                        (df_batch["quantitysold"] >= 0)]
    return df_batch


def run_apriori_analysis(df_sample):
    """
    H√†m th·ª±c hi·ªán ph√¢n t√≠ch gi·ªè h√†ng b·∫±ng thu·∫≠t to√°n Apriori.
    """
    df_basket = df_sample.groupby(['brandname', 'productid'])['quantitysold'].sum().unstack().fillna(0)
    df_basket = df_basket > 0  # Chuy·ªÉn th√†nh boolean

    if not df_basket.empty:
        # T√≠nh t·∫≠p m·ª•c ph·ªï bi·∫øn
        frequent_itemsets = apriori(df_basket, min_support=0.05, use_colnames=True)
        frequent_itemsets['itemsets'] = frequent_itemsets['itemsets'].apply(lambda x: ', '.join(map(str, list(x))))

        if not frequent_itemsets.empty:
            # T√≠nh lu·∫≠t k·∫øt h·ª£p
            rules = association_rules(frequent_itemsets, metric="lift", min_threshold=1.0, num_itemsets=10, support_only=True)
            rules['antecedents'] = rules['antecedents'].apply(lambda x: ', '.join(list(x)))
            rules['consequents'] = rules['consequents'].apply(lambda x: ', '.join(list(x)))
        else:
            rules = None
        return frequent_itemsets, rules
    else:
        return None, None

# Header
st.title("üõçÔ∏è Tiki E-commerce Analytics Dashboard")
st.markdown("---")

# Sidebar
with st.sidebar:
    st.header("B·ªô l·ªçc")
    price_range = st.slider(
        "Kho·∫£ng gi√° (VNƒê)",
        min_value=float(0),
        max_value=float(10000000),
        value=(0.0, 10000000.0)
    )
    min_rating = st.slider("ƒê√°nh gi√° t·ªëi thi·ªÉu", 0.0, 5.0, 0.0)
    
    st.markdown("---")
    st.markdown("### Th√¥ng tin c·∫≠p nh·∫≠t")
    last_update = st.empty()

# Load v√† c·∫≠p nh·∫≠t d·ªØ li·ªáu
new_batch = get_data_batch()
st.session_state.current_data = pd.concat([st.session_state.current_data, new_batch], ignore_index=True)
df = st.session_state.current_data

# Lo·∫°i b·ªè s·∫£n ph·∫©m c√≥ `ratingaverage == 0`
# df = df[df["ratingaverage"] > 0]

# L·ªçc d·ªØ li·ªáu
df_filtered = df[
    (df['price'] >= price_range[0]) & 
    (df['price'] <= price_range[1]) &
    (df['ratingaverage'] >= min_rating)
]

# Metrics t·ªïng quan
st.markdown("### üìä Ch·ªâ s·ªë t·ªïng quan")
metric1, metric2, metric3, metric4 = st.columns(4)
with metric1:
    st.metric("üì¶ T·ªïng s·ªë s·∫£n ph·∫©m", f"{len(df_filtered):,}")
with metric2:
    st.metric("üõí T·ªïng s·ªë l∆∞·ª£ng b√°n", f"{df_filtered['quantitysold'].sum():,}")
with metric3:
    st.metric("üí∞ Gi√° trung b√¨nh", f"{df_filtered['price'].mean():,.0f} VNƒê")
with metric4:
    st.metric("‚≠ê ƒê√°nh gi√° trung b√¨nh", f"{df_filtered['ratingaverage'].mean():.2f}/5")

st.markdown("---")

# Tab Layout
tab1, tab2, tab3 = st.tabs(["üìä Ph√¢n T√≠ch Gi√° v√† Th∆∞∆°ng Hi·ªáu", "‚≠ê ƒê√°nh Gi√° v√† T·ª∑ L·ªá Gi·∫£m Gi√°", "üìà Chi·∫øn L∆∞·ª£c Marketing"])

# Tab 1: Ph√¢n t√≠ch gi√° v√† th∆∞∆°ng hi·ªáu
with tab1:
    st.markdown("### üìä Ph√¢n T√≠ch Gi√° v√† Th∆∞∆°ng Hi·ªáu")
    col1, col2 = st.columns(2)

    with col1:
        # Bi·ªÉu ƒë·ªì ph√¢n b·ªë gi√°
        fig1 = px.histogram(
            df_filtered, 
            x='price',
            title='üìä Ph√¢n b·ªë gi√° s·∫£n ph·∫©m',
            labels={'price': 'Gi√° (VNƒê)', 'count': 'S·ªë l∆∞·ª£ng'},
            color_discrete_sequence=['#FF6B6B']
        )
        fig1.update_layout(
            plot_bgcolor='white',
            paper_bgcolor='white',
            margin=dict(t=40, l=40, r=40, b=40)
        )
        st.plotly_chart(fig1, use_container_width=True)

    with col2:
        # Bi·ªÉu ƒë·ªì Top th∆∞∆°ng hi·ªáu b√°n ch·∫°y nh·∫•t
        top_brands = df_filtered.groupby('brandname')['quantitysold'].sum().sort_values(ascending=True).tail(10)
        fig2 = go.Figure(go.Bar(
            x=top_brands.values,
            y=top_brands.index,
            orientation='h',
            marker_color='#4ECDC4'
        ))
        fig2.update_layout(
            title='üè¢ Top 10 th∆∞∆°ng hi·ªáu b√°n ch·∫°y nh·∫•t',
            plot_bgcolor='white',
            paper_bgcolor='white',
            margin=dict(t=40, l=200, r=40, b=40)
        )
        st.plotly_chart(fig2, use_container_width=True)

# Tab 2: Ph√¢n t√≠ch ƒë√°nh gi√° v√† t·ª∑ l·ªá gi·∫£m gi√°
with tab2:
    st.markdown("### ‚≠ê ƒê√°nh Gi√° v√† T·ª∑ L·ªá Gi·∫£m Gi√°")
    col1, col2 = st.columns(2)

    with col1:
        # Bi·ªÉu ƒë·ªì m·ªëi quan h·ªá gi·ªØa rating v√† s·ªë l∆∞·ª£ng b√°n
        fig3 = px.scatter(
            df_filtered, 
            x='ratingaverage', 
            y='quantitysold',
            title='‚≠ê M·ªëi quan h·ªá gi·ªØa ƒë√°nh gi√° v√† s·ªë l∆∞·ª£ng b√°n',
            labels={'ratingaverage': 'ƒêi·ªÉm ƒë√°nh gi√°', 'quantitysold': 'S·ªë l∆∞·ª£ng b√°n'},
            color='price',
            size='quantitysold',
            color_continuous_scale='Viridis'
        )
        fig3.update_layout(
            plot_bgcolor='white',
            paper_bgcolor='white',
            margin=dict(t=40, l=40, r=40, b=40)
        )
        st.plotly_chart(fig3, use_container_width=True)

    with col2:
        # Bi·ªÉu ƒë·ªì ·∫£nh h∆∞·ªüng c·ªßa t·ª∑ l·ªá gi·∫£m gi√° ƒë·∫øn s·ªë l∆∞·ª£ng b√°n
        fig4 = px.scatter(
            df_filtered, 
            x='discountrate', 
            y='quantitysold',
            title='üíØ ·∫¢nh h∆∞·ªüng c·ªßa t·ª∑ l·ªá gi·∫£m gi√° ƒë·∫øn s·ªë l∆∞·ª£ng b√°n',
            labels={'discountrate': 'T·ª∑ l·ªá gi·∫£m gi√° (%)', 'quantitysold': 'S·ªë l∆∞·ª£ng b√°n'},
            color='price',
            size='quantitysold',
            color_continuous_scale='Viridis'
        )
        fig4.update_layout(
            plot_bgcolor='white',
            paper_bgcolor='white',
            margin=dict(t=40, l=40, r=40, b=40)
        )
        st.plotly_chart(fig4, use_container_width=True)

# Tab 3: Chi·∫øn l∆∞·ª£c marketing
with tab3:
    st.markdown("### üìà Thu·∫≠t To√°n H·ªó Tr·ª£ Chi·∫øn L∆∞·ª£c Marketing")
    st.markdown("S·ª≠ d·ª•ng c√°c thu·∫≠t to√°n ƒë·ªÉ ph√¢n t√≠ch d·ªØ li·ªáu v√† ƒë∆∞a ra chi·∫øn l∆∞·ª£c kinh doanh.")

    if 'is_processing' not in st.session_state:
        st.session_state.is_processing = False

    # 1Ô∏è‚É£ N√∫t ch·ªçn m·∫´u d·ªØ li·ªáu
    if st.button("üóÇ Ch·ªçn m·∫´u d·ªØ li·ªáu"):
        with st.spinner("ƒêang l·∫•y m·∫´u d·ªØ li·ªáu..."):
            max_samples = 2000  # Gi·ªõi h·∫°n s·ªë m·∫´u
            df_sample = df_filtered.sample(n=min(len(df_filtered), max_samples), random_state=42)
            st.session_state["df_sample"] = df_sample  # L∆∞u v√†o session ƒë·ªÉ d√πng l·∫°i
        st.success(f"ƒê√£ ch·ªçn {len(df_sample)} m·∫´u d·ªØ li·ªáu!")

    # 2Ô∏è‚É£ Ph√¢n nh√≥m K-Means
    if st.button("üîç Ph√¢n Nh√≥m K-Means"):
        st.session_state.is_processing = True
    try:
        if "df_sample" in st.session_state:
            with st.spinner("ƒêang ph√¢n nh√≥m s·∫£n ph·∫©m..."):
                df_sample = st.session_state["df_sample"]
                features = ["price", "ratingaverage", "quantitysold"]
                df_clean = df_sample.dropna(subset=features)
                X = df_clean[features]

                if len(X) >= 3:
                    kmeans = KMeans(n_clusters=3, random_state=42)
                    df_clean["cluster"] = kmeans.fit_predict(X)

                    # Hi·ªÉn th·ªã bi·ªÉu ƒë·ªì
                    fig_kmeans = px.scatter_3d(
                        df_clean, x="price", y="ratingaverage", z="quantitysold",
                        color="cluster",
                        title="Ph√¢n Nh√≥m S·∫£n Ph·∫©m (K-Means Clustering)",
                        labels={"price": "Gi√° (VNƒê)", "ratingaverage": "ƒêi·ªÉm ƒë√°nh gi√°", "quantitysold": "S·ªë l∆∞·ª£ng b√°n"}
                    )
                    st.plotly_chart(fig_kmeans, use_container_width=True)
                    st.success("Ph√¢n nh√≥m s·∫£n ph·∫©m th√†nh c√¥ng!")
                else:
                    st.warning("D·ªØ li·ªáu kh√¥ng ƒë·ªß ƒë·ªÉ ph√¢n nh√≥m. H√£y ch·ªçn l·∫°i d·ªØ li·ªáu v·ªõi √≠t nh·∫•t 3 m·∫´u.")
    finally:
        st.session_state.is_processing = False

     # 3Ô∏è‚É£ Ph√¢n T√≠ch Gi·ªè H√†ng (Apriori)
    if st.button("üõí Ph√¢n T√≠ch Gi·ªè H√†ng (Apriori)"):
        st.session_state.is_processing = True
        try:
            if "df_sample" in st.session_state:
                df_sample = st.session_state["df_sample"]

                with st.spinner("ƒêang ph√¢n t√≠ch gi·ªè h√†ng..."):
                    # T·∫°o executor ƒë·ªÉ ch·∫°y ph√¢n t√≠ch gi·ªè h√†ng trong lu·ªìng ri√™ng
                    with concurrent.futures.ThreadPoolExecutor() as executor:
                        future = executor.submit(run_apriori_analysis, df_sample)
                        frequent_itemsets, rules = future.result()

                    if frequent_itemsets is not None:
                        st.write("Frequent Itemsets:")
                        st.dataframe(frequent_itemsets)
                        st.markdown(""" **Gi·∫£i nghƒ©a:** - **itemsets:** C√°c nh√≥m s·∫£n ph·∫©m th∆∞·ªùng ƒë∆∞·ª£c mua c√πng nhau. - **support:** T·∫ßn su·∫•t xu·∫•t hi·ªán c·ªßa nh√≥m s·∫£n ph·∫©m trong t·∫≠p d·ªØ li·ªáu (ph·∫ßn trƒÉm giao d·ªãch ch·ª©a nh√≥m s·∫£n ph·∫©m). """)

                        if rules is not None:
                            st.write("### C√°c lu·∫≠t k·∫øt h·ª£p ph·ªï bi·∫øn:")
                            st.dataframe(rules[["antecedents", "consequents", "support", "confidence", "lift"]])
                            st.markdown(""" **Gi·∫£i nghƒ©a:** - **antecedents:** T·∫≠p s·∫£n ph·∫©m xu·∫•t hi·ªán tr∆∞·ªõc. - **consequents:** T·∫≠p s·∫£n ph·∫©m ƒë∆∞·ª£c mua th√™m khi ƒë√£ mua t·∫≠p antecedents. - **support:** T·ª∑ l·ªá giao d·ªãch ch·ª©a c·∫£ antecedents v√† consequents. - **confidence:** X√°c su·∫•t mua consequents khi ƒë√£ mua antecedents. - **lift:** M·ª©c ƒë·ªô li√™n k·∫øt gi·ªØa antecedents v√† consequents, gi√° tr·ªã >1 cho th·∫•y c√≥ m·ªëi quan h·ªá m·∫°nh. """)
                            st.success("Ph√¢n t√≠ch gi·ªè h√†ng th√†nh c√¥ng!")
                        else:
                            st.warning("Kh√¥ng t√¨m th·∫•y t·∫≠p m·ª•c ph·ªï bi·∫øn n√†o. H√£y th·ª≠ gi·∫£m gi√° tr·ªã min_support.")
                    else:
                        st.warning("D·ªØ li·ªáu gi·ªè h√†ng r·ªóng. Vui l√≤ng ki·ªÉm tra b·ªô l·ªçc ho·∫∑c ngu·ªìn d·ªØ li·ªáu!")
            else:
                st.warning("B·∫°n c·∫ßn ch·ªçn m·∫´u d·ªØ li·ªáu tr∆∞·ªõc khi ch·∫°y thu·∫≠t to√°n Apriori!")
        finally:
            st.session_state.is_processing = False




# Footer
st.markdown("---")
st.markdown("""
    <div style='text-align: center'>
        <p>Made with ‚ù§Ô∏è by H·ªØu H·∫≠u</p>
    </div>
""", unsafe_allow_html=True)

# C·∫≠p nh·∫≠t th·ªùi gian
last_update.text(f"C·∫≠p nh·∫≠t l·∫ßn cu·ªëi: {datetime.now().strftime('%H:%M:%S')}")

# TƒÉng index cho l·∫ßn load ti·∫øp theo
if st.session_state.start_idx < get_total_records():
    st.session_state.start_idx += st.session_state.batch_size

# Auto refresh
time.sleep(random.uniform(1,5))
st.rerun()